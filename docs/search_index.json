[["index.html", "ML Guide Preface", " ML Guide Greg Rompala 2020-10-22 Preface Iterative machine learning regression modeling.Build models for multiple traits with multiple important feature number cut-offs. Data Visualization techniques using ggplot2 and gganimate. "],["supervised-regression-modelling.html", "Chapter 1 Supervised Regression Modelling 1.1 Training and Testing 1.2 Examining the Results", " Chapter 1 Supervised Regression Modelling This is the basic framework. Nested CV will allow for using several training-test paritions in parallel in the outer loop. The inner-loop features cross-validation with 5 folds of the training data. Finally, backward selection of gene features allows you to build new models with a specified amout of most important features as determined from the training model. 1.1 Training and Testing Here we are going to use placental gene expression to predict maternal age and emotional regulation in children. # Load necessary packages suppressPackageStartupMessages({ library(caret) library(DESeq2) library(e1071) library(pROC) library(plyr) library(stringr) library(dplyr) library(mboost) library(gbm) library(DESeq2) library(dplyr) library(pls) library(ggplot2) library(ggpubr) library(gganimate) library(gapminder) library(cowplot) library(directlabels) library(gifski) library(transformr) library(RUncommon) }) # working.dir=&quot;C:/Users/grrompala/Desktop&quot; # working directory # setwd(working.dir) # Load in your gene counts and metadata counts &lt;- read.csv(&quot;counts.csv&quot;,header=T,row.names=1) # raw gene counts for each subject meta &lt;- read.csv(&quot;meta.csv&quot;,header=T,row.names=1) # metadata with 2 outcomes we will predict for each subject head(counts[1:10,1:10]) ## S_1 S_10 S_100 S_103 S_106 S_107 S_108 S_109 S_10Q S_11 ## A1BG-AS1 16 16 16 14 23 15 26 16 13 9 ## A2M 30620 14070 24203 31400 43652 30419 34490 22477 33795 10351 ## A2M-AS1 20 18 38 28 17 27 27 29 22 12 ## A2ML1 165 22 7 4 31 8 14 10 13 18 ## A2MP1 3 3 18 16 5 1 19 23 11 12 ## A4GALT 1168 516 702 607 1147 462 687 822 628 622 head(meta[1:10,]) ## STAI_TTO REG ## S_1 20 6.583333 ## S_10 34 4.345238 ## S_100 36 4.960000 ## S_103 27 6.232143 ## S_106 41 5.540000 ## S_107 31 4.600000 # Filter and normalize gene counts: we will use rowMeans&gt;10 as a filter counts &lt;- counts[rowMeans(counts)&gt;10,] counts &lt;- varianceStabilizingTransformation(as.matrix(counts)) counts &lt;- t(counts) # Filter metadata and subjects that are missing metadata for mom age or child emotional regulation Here we will employ common techniques employed to reduce number of predictors that may be introducing noise # Filter counts by coefficient of variance coef.var&lt;-apply(subset(counts),2,function(x)sd(x)/mean(x)) # calculate coefficent of variance (CV) genes2keep&lt;-names(coef.var)[which(coef.var&gt;0.05)] # extract genes to keep after CV threshold coef_counts&lt;-counts[,c(genes2keep)] # filter by genes to keep #paste(&quot;Number of Genes Remaining:&quot;,length(colnames(coef_counts)),sep=&quot; &quot;) # Filter counts using dimensionality reduction CorrelationMatrix&lt;-cor(coef_counts[,-1]) highlyCorrelated&lt;-findCorrelation(CorrelationMatrix,cutoff=0.9,names=TRUE) # Filters genes with correlation R values greater than 0.8 (keeping the gene with least co-linearity) COUNTS &lt;-coef_counts[,setdiff(colnames(coef_counts),highlyCorrelated)] paste(&quot;Number of Genes Remaining:&quot;,length(colnames(COUNTS)),sep=&quot; &quot;) ## [1] &quot;Number of Genes Remaining: 5885&quot; set.seed(1097) # Set seed for reproducible results! Now, we will loop through our two outcome variables, building a partial least squares regression model for each #global-options,include=TRUE,warning=FALSE} #knitr::opts_chunk$set(warning=FALSE,message=FALSE,include=FALSE) # Settings to repress warning messages in the chunk options(width = 60) outcomes &lt;- colnames(meta) # should be mother&#39;s trait anxiety and emotional regulation as vector model &lt;- c(&quot;glmnet&quot;) # set model variables &lt;- c(100,1000,5000) # Set how many ranked important variables to rebuild model with # Initialize data summaries final.summary &lt;- data.frame(Buffer=character(),stringsAsFactors = FALSE) all.predictions &lt;- data.frame(holder=character(), stringsAsFactors=FALSE) resample.summary &lt;- data.frame(holder=character(), stringsAsFactors=FALSE) varImp.summary &lt;- data.frame(blank=&quot;&quot;) # Looping through both traits and both features cut-offs (100,1000) for (trait in outcomes) { metaF &lt;- meta %&gt;% filter(is.na(meta[[trait]])==F) # filter out NAs from outcome variable counts &lt;- COUNTS[rownames(metaF),] # filter subjects in counts with new metadata working.META &lt;- metaF[[trait]] # filters metadata for outcome names(working.META) &lt;- rownames(metaF) train.parts &lt;- createDataPartition(working.META,p=0.8,list=TRUE,times=10) # makes training and test sets #(Here I am making 25 training-test splits of 80% train and 20% test) cv.settings &lt;- trainControl(method=&quot;repeatedcv&quot;,number=5,repeats=3) # cross-validation with #splits data into 5 folds and repeats this three times # Train regression model for each of your partitions Regression.Models &lt;-lapply(train.parts, function(L){ X.train &lt;- counts[L,] Y.train &lt;- working.META[L] train.parts &lt;- rownames(X.train) model.one &lt;-train(y=Y.train, x=X.train, method=model, trControl = cv.settings, trace=FALSE) importance&lt;- varImp(model.one)$importance # outputs variables ranked by importance score TrainID&lt;-names(Y.train) return(list(MODEL=model.one,TrainID=TrainID,importance=importance,train.parts=train.parts)) }) # Empty DFs to iterate through different feature variable cut-offs df &lt;- data.frame(New=character(), stringsAsFactors=FALSE) predictionsT &lt;- data.frame(New=character(), stringsAsFactors=FALSE) resamplesT &lt;- data.frame(New=character(), stringsAsFactors=FALSE) for (import_num in variables) # Choose a few important variable cutoffs { VarImport.Models &lt;- lapply(Regression.Models, function(L){ importance &lt;- L$importance varImps &lt;- rownames(importance[order(importance$Overall,decreasing=T),,drop=FALSE])[1:import_num] varImps &lt;- str_remove_all(varImps,&quot;`&quot;) train.parts &lt;- L$train.parts X.train&lt;- counts[train.parts,varImps] Y.train&lt;- working.META[train.parts] model.one &lt;-train(y=Y.train, x=X.train, method=model, trControl = cv.settings, trace=FALSE) TrainID&lt;-names(Y.train) return(list(MODEL=model.one,TrainID=TrainID,varImps=varImps))}) # Compile model results VarImport.Models.Results &lt;- lapply(VarImport.Models,function(L){ ok&lt;- getTrainPerf(L$MODEL) return(ok) }) RM.Results &lt;- ldply(VarImport.Models.Results,rbind) # Use trained model on test dataset Regression.Predictions&lt;-lapply(VarImport.Models, function(L){ TrainID&lt;-L$TrainID TestID&lt;-setdiff(rownames(counts),TrainID) MODEL&lt;-L$MODEL varImps &lt;- L$varImps X.test&lt;- counts[TestID,varImps] Y.test&lt;-working.META[TestID] model.preds&lt;-predict(MODEL,X.test) table.preds&lt;-cbind.data.frame(PRED=model.preds,REAL=Y.test) table.preds$SampleID&lt;-rownames(table.preds) RMSE &lt;- RMSE(model.preds,Y.test) correlation &lt;- cor(model.preds,Y.test) return(list(testRMSE=RMSE,table.preds=table.preds,testR=correlation))}) # Generate best RMSEs and correlation R values for all test partitions RMSE &lt;- lapply(Regression.Predictions,function(L){ RMSE &lt;- L$testRMSE return(RMSE)}) RMSE &lt;-do.call(&quot;rbind.data.frame&quot;,RMSE) colnames(RMSE) &lt;- NULL # Get correlation between predictions and real scores for each train-test partition corr &lt;- lapply(Regression.Predictions,function(L){ corr &lt;- L$testR return(corr)}) corr &lt;-do.call(&quot;rbind.data.frame&quot;,corr) colnames(corr) &lt;- NULL # Compile results for each resample results &lt;- cbind(RM.Results,RMSE,corr) results$trait &lt;- trait results$var.num &lt;- import_num resamplesT &lt;- rbind.fill(resamplesT,results) ## Compile results summarizing each resample per trait and number of features RM.Result &lt;- RM.Results[,2:4] averages &lt;- cbind(RM.Result,RMSE,corr) averagez &lt;- colMeans(averages) averages &lt;- append(trait,averagez) averages &lt;- append(import_num,averages) x &lt;- data.frame(t(averages)) colnames(x)[1:2] &lt;- c(&quot;Feature.number&quot;,&quot;Trait&quot;) df &lt;- rbind.fill(df,x) ## Bind and write all predictions out to file Regression.Predictions &lt;- lapply(Regression.Predictions,function(L){ Regression.Predictions &lt;- L$table.preds return(Regression.Predictions)}) Regression.Predictions &lt;- mapply(`[&lt;-`, Regression.Predictions, &#39;Partition&#39;, value = names(Regression.Predictions), SIMPLIFY = FALSE) Regression.Predictions &lt;- bind_rows(Regression.Predictions) Regression.Predictions$trait &lt;- trait Regression.Predictions$feat.num &lt;- as.factor(import_num) predictionsT &lt;- rbind.fill(predictionsT,Regression.Predictions) # print(paste(import_num,&quot;done&quot;,sep=&quot; &quot;) } # Write gene importance out to file varImp.list &lt;-lapply(Regression.Models, function(L){ importance&lt;-varImp(L$MODEL) return(importance$importance)}) varImp.list &lt;- do.call(&quot;cbind&quot;,varImp.list) colnames(varImp.list) &lt;- c(paste(&quot;Resample.&quot;,1:length(colnames(varImp.list)),sep=&quot;&quot;)) avg.varImp &lt;- rowMeans(varImp.list) # Bind results for each trait used varImp.summary &lt;- cbind(varImp.summary,avg.varImp) final.summary &lt;- rbind.fill(final.summary,df) all.predictions &lt;- rbind.fill(all.predictions,predictionsT) resample.summary &lt;- rbind.fill(resample.summary,resamplesT) } Clean up the results data frames and perhaps write results to file # remove excess all.predictions &lt;- all.predictions[,-c(1:2)] resample.summary &lt;- resample.summary[,-c(1:2)] final.summary &lt;- final.summary[,-c(1:2)] varImp.summary &lt;- varImp.summary[,-1] colnames(varImp.summary) &lt;- outcomes # write.csv(final.summary[,-c(1:2)],file=&quot;Summary.REG.varImp.GLMNET.csv&quot;) # write.csv(all.predictions[,-1],file=&quot;PREDICTIONS.REG.varImp.GLMNET.csv&quot;) # write.csv(resample.summary,file=&quot;Resample.REG.varImp.GLMNET.csv&quot;) # write.csv(varImp.summary,file=&quot;VarImp.summary.csv&quot;) 1.2 Examining the Results Here we depict predictions vs real values. Note all subjects are represented as we took the average prediction across all 10 test partitions. # results for emtoional regulation ok &lt;- ggscatter(all.predictions %&gt;% filter(trait==&quot;REG&quot;), x=&quot;PRED&quot;, y=&quot;REAL&quot;, color=&quot;feat.num&quot;, add=&quot;reg.line&quot;, mean.point = T, title=&quot;Predicting Emotional Regulation from Placental Gene Expression&quot;, mean.point.size=9, palette=&quot;Set2&quot;, facet.by = &quot;feat.num&quot;, xlab=&quot;PREDICTED VALUE&quot;, ylab=&quot;REAL VALUE&quot;)+ stat_cor(method = &quot;pearson&quot;,show.legend = F)+ theme(plot.title = element_text(hjust = 0.5)) ok &lt;- ggpar(ok,legend.title= &quot;Number of Important Features&quot;,legend=&quot;bottom&quot;) ok ## `geom_smooth()` using formula &#39;y ~ x&#39; The same thing here, just using gganimate p &lt;- ggplot(all.predictions %&gt;% filter(trait==&quot;REG&quot;), aes(x=PRED, y=REAL)) + geom_point(alpha = 0.7, show.legend = FALSE) + geom_smooth(method=&#39;lm&#39;, formula= y~x)+ stat_smooth_func(geom=&quot;text&quot;,method=&quot;lm&quot;,hjust=0,parse=TRUE)+ # stat_regline_equation()+ #scale_colour_manual(values = country_colors) + #scale_size(range = c(2, 12)) + #scale_x_log10() + #facet_wrap(~continent) + # Here comes the gganimate specific bits labs(title=&quot;Child Emotional Regulation&quot;,subtitle = &quot;Number of Features: {closest_state}&quot;, x = &#39;PREDICTED&#39;, y = &#39;REAL&#39;) + transition_states(feat.num) + theme( plot.title = element_text(face=&quot;bold&quot;) ) animate(p, duration = 5, fps = 50, width = 500, height = 500, renderer = gifski_renderer()) #anim_save(&quot;output.gif&quot;) RMSE (Root Mean Square Error) is used to evaluate test performance. This tells you the average difference between the real and predicted values (i.e, the residual). resample.stat &lt;- resample.summary %&gt;% filter(trait==&quot;REG&quot;) %&gt;% group_by(var.num) %&gt;% summarise( mean=mean(RMSE), se=sd(RMSE)/sqrt(n())) ggplot(resample.stat,aes(x=var.num,y=mean))+ geom_line(color=&quot;black&quot;,size=1)+ geom_point(color=&quot;red&quot;,size=5)+ geom_errorbar(aes(ymin = mean - se, ymax = mean + se), color=&quot;red&quot;,width=300,size=1)+ labs(title=&quot;Emotional Regulation: Test Performance&quot;, x = &#39;Features&#39;, y = &#39;Mean RMSE&#39;,hjust=0.5)+ scale_x_continuous(breaks=c(100,1000,5000))+ ylim(0.5,.75)+ theme(plot.title=element_text(size=18,face=&quot;bold&quot;), axis.title=element_text(size=14,face=&quot;bold&quot;), axis.text.x = element_text(size=12), axis.text.y=element_text(size=12)) Showing how RMSE changed with each resampling test partition resample.summary$ID &lt;- rep(1:10,times=6,each=1) p &lt;- ggplot(resample.summary %&gt;% filter(trait==&quot;REG&quot;), aes(x=ID, y=RMSE,group=as.factor(var.num),color=as.factor(var.num))) + geom_line()+ geom_point(alpha = 0.7, show.legend = FALSE) + scale_x_continuous(breaks=c(1:10))+ scale_color_discrete(name=&quot;Number of Impotant Features&quot;)+ labs(x=&quot;Resample number&quot;,y=&quot;RMSE&quot;,title=&quot;Emotional Regulation:Test Performance&quot;)+ transition_reveal(ID) + theme( plot.title = element_text(face=&quot;bold&quot;) ) animate(p, duration = 8, fps = 50, width = 700, height = 500, renderer = gifski_renderer(),end_pause = 100) #anim_save(&quot;output.gif&quot;) Taking a look at most important variables for each trait ## Sort by highest importance to lowest #m &lt;- varImp.summary %&gt;% arrange(desc(REG)) #ggplot(aes(x=`car name`, y=mpg_z, label=mpg_z)) + #geom_bar(stat=&#39;identity&#39;, aes(fill=mpg_type), width=.5) + # scale_fill_manual(name=&quot;Mileage&quot;, # labels = c(&quot;Above Average&quot;, &quot;Below Average&quot;), # values = c(&quot;above&quot;=&quot;#00ba38&quot;, &quot;below&quot;=&quot;#f8766d&quot;)) + #labs(subtitle=&quot;Normalised mileage from &#39;mtcars&#39;&quot;, # title= &quot;Diverging Bars&quot;) + # coord_flip() Show test predictions for every subject: You can see the predictions are quite conservative DF &lt;- all.predictions %&gt;% filter(trait==&quot;REG&quot; &amp; feat.num==5000) %&gt;% arrange(REAL) %&gt;% mutate(Order=1:nrow(.)) ONE &lt;- DF %&gt;% select(PRED,SampleID,Order) %&gt;% mutate(LABEL=&quot;PREDICTION&quot;) TWO &lt;- DF %&gt;% select(REAL,SampleID,Order) %&gt;% mutate(LABEL=&quot;REAL VALUE&quot;) colnames(TWO)[1] &lt;- &quot;PRED&quot; all.pred &lt;- rbind(ONE,TWO) ggplot(all.pred %&gt;% filter(trait==&quot;REG&quot;), aes(x=PRED, y=reorder(SampleID,Order),color=LABEL)) + geom_point(alpha = 0.7,size=3)+ labs(title=&quot;Predicting Child Emotional Regulation&quot;, x = &#39;Emotional Regulation Score&#39;, y = &#39;Subjects&#39;) + scale_color_manual(values=c(&quot;#FF0000&quot;,&quot;#0000FF&quot;),)+ #scale_x_continuous(labels=) theme( plot.title = element_text(face=&quot;bold&quot;), axis.text.x = element_text(size=12), axis.text.y = element_text(size=6), axis.title.x=element_text(face=&quot;bold&quot;), axis.title.y=element_text(face=&quot;bold&quot;), panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size=5)) "],["multitask-mvtboost-for-predicting-multiple-behaviors-from-placental-transcriptome.html", "Chapter 2 Multitask mvtboost for predicting multiple behaviors from placental transcriptome  2.1 compare best alpha across train-test partitions", " Chapter 2 Multitask mvtboost for predicting multiple behaviors from placental transcriptome  suppressPackageStartupMessages({ library(glmnet) # Loads glmnet package library(caret) library(plyr) library(gganimate) library(gapminder) library(cowplot) library(directlabels) library(gifski) library(transformr) library(RUncommon) library(tidyr) library(broom) }) ## Warning: package &#39;transformr&#39; was built under R version 4.0.3 ## Warning: package &#39;broom&#39; was built under R version 4.0.3 #working.dir=&quot;C:/Users/grrompala/Desktop&quot; # working directory #setwd(working.dir) ## Import counts and metadata as matrix [make sure there are no NAs] counts &lt;- read.csv(&quot;counts.csv&quot;,header=T,row.names=1) meta &lt;- as.matrix(read.csv(&quot;meta.csv&quot;,header=T,row.names=1)) counts &lt;- as.matrix(t(counts[,rownames(meta)])) Set seed for reproducibility set.seed(777) Determine Training and Test Sets: making 3 training:test partitions here Y.cont &lt;- meta[,1] # replace with variable of choice names(Y.cont) &lt;- rownames(meta) train.parts &lt;- createDataPartition(Y.cont,p=.8,list=TRUE,times=3) Cross-validation training options(width = 60) out &lt;- lapply(train.parts,function(L){ ## Cross-validation training list.of.fits &lt;- list() for (i in 0:10) { ## Here&#39;s what&#39;s going on in this loop... ## We are testing alpha = i/10. This means we are testing ## alpha = 0/10 = 0 on the first iteration, alpha = 1/10 = 0.1 on ## the second iteration etc. ## First, make a variable name that we can use later to refer ## to the model optimized for a specific alpha. ## For example, when alpha = 0, we will be able to refer to ## that model with the variable name &quot;alpha0&quot;. fit.name &lt;- paste0(&quot;alpha&quot;, i/10) ## Now fit a model (i.e. optimize lambda) and store it in a list that ## uses the variable name we just created as the reference. list.of.fits[[fit.name]] &lt;- cv.glmnet(counts[L,], meta[L,],nfolds=10, type.measure=&quot;mse&quot;, alpha=i/10, family=&quot;mgaussian&quot;) } return(list(FITS=list.of.fits)) }) 2.1 compare best alpha across train-test partitions new &lt;- lapply(out,function(L){ lambda.min &lt;- vector() for(x in 1:11){ x&lt;- L$FITS[[x]]$lambda.min lambda.min &lt;- append(lambda.min,x) } return(lambda.min) }) # Final lambda.se NAMES &lt;- names(out$Resample1$FITS) lambda &lt;- ldply(new,rbind) colnames(lambda)[2:12] &lt;- NAMES Inspect the minimum lambda values for each alpha. #resample.summary$ID &lt;- rep(1:10,times=6,each=1) LAMBDA &lt;- gather(lambda,key=&quot;Alpha&quot;,value =&quot;Lambda&quot;,-.id ) LAMBDA$Alpha &lt;- stringr::str_replace_all(LAMBDA$Alpha,&quot;alpha&quot;,&quot;&quot;) LAMBDA$Alpha &lt;- as.numeric(LAMBDA$Alpha) p &lt;- ggplot(LAMBDA, aes(x=Alpha, y=Lambda,group=as.factor(.id),color=as.factor(.id))) + geom_line()+ geom_point(alpha = 0.7, show.legend = FALSE) + scale_x_continuous(breaks=seq(0,1,by=0.1))+ ylim(0,40)+ scale_color_discrete(name=&quot;Comparing Best Lambda&quot;)+ labs(x=&quot;Alpha value&quot;,y=&quot;Lambda.min&quot;,title=&quot;Best Lambda&quot;)+ # transition_reveal(Alpha) + ## If you want to animate theme( plot.title = element_text(face=&quot;bold&quot;) ) # If you want to animate #animate(p, duration = 8, fps = 50, width = 700, height = 500, renderer = gifski_renderer(),end_pause = 100) p ## Warning: Removed 4 row(s) containing missing values ## (geom_path). ## Warning: Removed 4 rows containing missing values ## (geom_point). Now we see which alpha (0, 0.1,  , 0.9, 1) does the best job predicting the values in the Testing dataset. results &lt;- data.frame() predicted &lt;- list() ticker &lt;- 1 mine &lt;- lapply(out,function(L){ for (i in 0:10) { fit.name &lt;- paste0(&quot;alpha&quot;, i/10) x &lt;- train.parts[[ticker]] ## Use each model to predict &#39;y&#39; given the Testing dataset predicted[[fit.name]] &lt;- predict(L$FITS[[fit.name]], s=L$FITS[[fit.name]]$lambda.min,newx=counts[-x,]) # lamda.1se gives me same values for all) dat.ANX &lt;- data.frame(predicted[[fit.name]])[,1] dat.REG &lt;- data.frame(predicted[[fit.name]])[,2] ## Calculate the Mean Squared Error... mse.ANX &lt;- mean((meta[-x,1]-dat.ANX)^2) cor.ANX &lt;- cor(meta[-x,1],dat.ANX) mse.REG &lt;- mean((meta[-x,2]-dat.REG)^2) cor.REG &lt;- cor(meta[-x,2],dat.REG) ## Store the results temp &lt;- data.frame(alpha=i/10, mse.ANX=mse.ANX,mse.REG=mse.REG,cor.ANX=cor.ANX,cor.REG=cor.REG) results &lt;- rbind(results, temp) } ticker &lt;- ticker+1 results }) mine ## $Resample1 ## alpha mse.ANX mse.REG cor.ANX cor.REG ## 1 0.0 157.8251 0.2165756 0.040650580 0.341055253 ## 2 0.1 153.6521 0.3739259 0.176143832 -0.017137171 ## 3 0.2 151.7553 0.2571316 0.004829493 -0.139928415 ## 4 0.3 148.8318 0.2534180 -0.009199660 -0.167371783 ## 5 0.4 152.2548 0.2593742 -0.006625847 -0.170220235 ## 6 0.5 150.7424 0.2548932 -0.005101073 -0.111918250 ## 7 0.6 148.4390 0.2512730 0.020025030 -0.073011263 ## 8 0.7 148.4599 0.2505917 0.027812628 -0.040937734 ## 9 0.8 146.5394 0.2485602 0.067237517 -0.004105224 ## 10 0.9 156.2203 0.2510810 0.054945504 0.053600964 ## 11 1.0 146.8357 0.2460869 NA NA ## ## $Resample2 ## alpha mse.ANX mse.REG cor.ANX cor.REG ## 1 0.0 139.71511 0.2060069 0.3788515 0.497241026 ## 2 0.1 144.66249 0.2411485 0.4993212 -0.210051029 ## 3 0.2 123.97687 0.2395855 0.6204862 0.043585700 ## 4 0.3 146.75561 0.2400418 NA NA ## 5 0.4 131.06258 0.2442514 0.5634437 -0.086731526 ## 6 0.5 122.11802 0.2427125 0.6148530 0.001088167 ## 7 0.6 95.37157 0.2297153 0.7142508 0.212751398 ## 8 0.7 113.52932 0.2400026 0.6381474 0.089176697 ## 9 0.8 86.45743 0.2252484 0.7253725 0.262772761 ## 10 0.9 76.54971 0.2177523 0.7449105 0.321737577 ## 11 1.0 83.71461 0.2146711 0.7261630 0.352089566 ## ## $Resample3 ## alpha mse.ANX mse.REG cor.ANX cor.REG ## 1 0.0 104.23937 0.1433687 0.6443336 0.677447286 ## 2 0.1 146.95428 0.2432270 NA NA ## 3 0.2 68.67570 0.2006735 0.8475218 0.494744890 ## 4 0.3 146.95428 0.2432270 NA NA ## 5 0.4 146.95428 0.2432270 NA NA ## 6 0.5 105.43017 0.2409735 0.7432870 0.086508980 ## 7 0.6 110.14788 0.2435018 0.7353679 0.016053736 ## 8 0.7 106.83652 0.2443347 0.7481970 0.002752367 ## 9 0.8 146.95428 0.2432270 NA NA ## 10 0.9 100.26308 0.2478571 0.7596765 -0.047267614 ## 11 1.0 91.84076 0.2523996 0.7597162 -0.090806251 Get top coefficients bb &lt;- coef(out$Resample1$FITS$alpha0.1,s=out$Resample1$FITS$alpha0.1$lambda.min) ANX.COEF &lt;- tidy(bb$STAI_TTO) REG.COEF &lt;- tidy(bb$REG) #Top positive coefficients REG.COEF %&gt;% arrange(desc(value)) %&gt;% head(n=10) ## row column value ## 1 (Intercept) 1 5.290904793 ## 2 FAM71E1 1 0.003913448 ## 3 SLC12A9-AS1 1 0.003758733 ## 4 SMC1B 1 0.003063004 ## 5 RAB33A 1 0.002953823 ## 6 SMG1P6 1 0.002689962 ## 7 TTC4 1 0.002635864 ## 8 RN7SKP80 1 0.002518529 ## 9 HCG25 1 0.002492880 ## 10 SMC5-AS1 1 0.002382001 ANX.COEF %&gt;% arrange(desc(value)) %&gt;% head(n=10) ## row column value ## 1 (Intercept) 1 23.74961672 ## 2 SLC12A9-AS1 1 0.03831273 ## 3 MIR320E 1 0.02864717 ## 4 SMG1P6 1 0.02571635 ## 5 TMEM110-MUSTN1 1 0.02477292 ## 6 DLEU2L 1 0.02366440 ## 7 URAHP 1 0.02339192 ## 8 SMC1B 1 0.02310373 ## 9 MAP1LC3B2 1 0.02304964 ## 10 ELOA-AS1 1 0.02207229 #Top negative coefficients REG.COEF %&gt;% arrange(value) %&gt;% head(n=10) ## row column value ## 1 PKD2L2 1 -0.004160983 ## 2 Z73965.1 1 -0.004033330 ## 3 MAP1LC3B2 1 -0.003156425 ## 4 CADM2 1 -0.002682255 ## 5 PMS2P6 1 -0.002630137 ## 6 ALG1L2 1 -0.002607562 ## 7 NODAL 1 -0.002595879 ## 8 NOXRED1 1 -0.002311842 ## 9 IQUB 1 -0.002070080 ## 10 CD160 1 -0.001994387 ANX.COEF %&gt;% arrange(value) %&gt;% head(n=10) ## row column value ## 1 PABPC1P4 1 -0.02855627 ## 2 SMC5-AS1 1 -0.02671643 ## 3 GLIDR 1 -0.02238008 ## 4 PMS2P6 1 -0.02209330 ## 5 SLIT1 1 -0.02095026 ## 6 LINC02606 1 -0.01951022 ## 7 RN7SKP80 1 -0.01770279 ## 8 ATE1-AS1 1 -0.01617622 ## 9 MYB 1 -0.01551098 ## 10 VPS33B 1 -0.01518836 "]]
